Research Article

Received 21 April 2016,

Accepted 19 May 2017

(wileyonlinelibrary.com) DOI: 10.1002/sim.7368

Published online 12 June 2017 in Wiley Online Library

Information criteria for Firthâ€™s penalized partial likelihood approach in Cox regression models

Kengo Nagashima*â€  and Yasunori Sato

In the estimation of Cox regression models, maximum partial likelihood estimates might be infinite in a monotone likelihood setting, where partial likelihood converges to a finite value and parameter estimates converge to infinite values. To address monotone likelihood, previous studies have applied Firthâ€™s bias correction method to Cox regression models. However, while the model selection criteria for Firthâ€™s penalized partial likelihood approach have not yet been studied, a heuristic AIC-type information criterion can be used in a statistical package. Application of the heuristic information criterion to data obtained from a prospective observational study of patients with multiple brain metastases indicated that the heuristic information criterion selects models with many parameters and ignores the adequacy of the model. Moreover, we showed that the heuristic information criterion tends to select models with many regression parameters as the sample size increases. Thereby, in the present study, we propose an alternative AIC-type information criterion based on the risk function. A Bayesian information criterion type was also evaluated. Further, the presented simulation results confirm that the proposed criteria performed well in a monotone likelihood setting. The proposed AIC-type criterion was applied to prospective observational study data. Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd
Keywords: Akaikeâ€™s information criterion; model selection; monotone likelihood; penalized partial likelihood; survival analysis

1. Introduction
The Cox regression model [1] is one of the most useful and widely used tools in survival analysis. In Cox regression model estimations, maximum partial likelihood estimates may be infinite in monotone likelihood situations [2]. In such cases, partial likelihood converges to a finite value, and the parameter estimates and standard errors converge to infinite values; hence, these results are not interpretable. Such problems arise, for example, in the presence of unbalanced covariates, large parameter effects, and/or heavy censoring.
To address this monotone likelihood problem, Heinze and Schemper proposed Firthâ€™s penalized partial likelihood approach [3]. They directly applied to the Cox regression model Firthâ€™s bias correction method [4], which aims to remove asymptotic bias from maximum likelihood estimates in exponential families with canonical link functions. Firthâ€™s penalized partial likelihood approach reduces asymptotic bias and addresses the monotone likelihood problem [3, 5]. Firthâ€™s bias correction method was also applied to logistic regression models to address the separation problem [5â€“7], which is similar to the monotone likelihood problem. This approach reduces asymptotic bias and also overcomes the separation problem.
In this study, we discuss the model selection criteria for Firthâ€™s penalized partial likelihood approach based on Akaikeâ€™s information criterion (AIC) [8] and Bayesian information criterion (BIC) [9]. Although

Department of Global Clinical Research, Graduate School of Medicine, Chiba University, 1-8-1 Inohana, Chuo-ku, Chiba
260-8670, Japan *Correspondence to: Kengo Nagashima, Department of Global Clinical Research, Graduate School of Medicine, Chiba
University, 1-8-1 Inohana, Chuo-ku, Chiba 260-8670, Japan. â€ E-mail: nshi@chiba-u.jp The copyright line for this article was changed on 20 November 2017 after original online publication. This is an open access article under the terms of the Creative Commons Attribution-NonCommercial License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited and is not used for commercial purposes.

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

3422

K. NAGASHIMA AND Y. SATO
model selection is an important issue in data analysis, the model selection criteria for Firthâ€™s penalized partial likelihood approach have never been studied. To our best knowledge, only the SAS PHREG procedure can be used to obtain an AIC-type heuristic information criterion, AICâˆ— = âˆ’2log(maximum penalized partial likelihood)+2p, where p is the number of regression parameters, and other major statistical software (e.g., Stata and R) can only output the log penalized partial likelihood. However, AICâˆ— is not theoretically justified, and especially, we find that AICâˆ— tends to select a model that has a large number of regression parameters as n â†’ âˆž, where n is the sample size; that is, AICâˆ— does not have the important property of avoiding over-fitting. This result indicates that AICâˆ— is not a suitable model selection criterion. Similarily, the SAS PHREG procedure implements a BIC-type heuristic information criterion, BICâˆ— = âˆ’2log(maximum penalized partial likelihood)+ log d, where d is the number of events. BICâˆ— is not also theoretically justified. Therefore, we consider alternative model selection criteria in this setting.
The remainder of this paper is organized as follows. In Section 2, we introduce motivating data and issues of AICâˆ—. Section 3 briefly reviews Firthâ€™s bias correction method and penalized partial likelihood approach, discusses the fundamental problems of AICâˆ— and BICâˆ—, and proposes appropriate information criteria. Section 4 presents the simulation results to demonstrate the performance of the criteria and to check the property of AICâˆ— holds. Section 5 applies the proposed method to real data, and Section 6 concludes the paper with a brief discussion.
2. Motivating example
Yamamoto et al. [10] collected time-to-event (e.g., death, local recurrence, and leptomeningeal dissemination) data for 1194 cancer patients with multiple brain metastases. Secondary end points of this study include time to leptomeningeal dissemination (the data on 928 patients were censored, while the MRI results of 121 patients (10%), that is, those who suffered an early death or who deteriorated markedly soon after stereotactic radiosurgery, were not available; 145 patients had an event). We analyzed the following covariates: age (<65, â‰¥65), sex (female, male), kps (Karnofsky performance status; â‰¥80, â‰¤70), ntumor (number of tumors; 1, 2â€“4, 5â€“10), diameter (maximum diameter of largest tumor; <1.6 cm, â‰¥1.6 cm), volume (cumulative tumor volume; <1.9 mL, â‰¥1.9 mL), ptumor (primary tumor category; lung, breast, gastrointestinal, kidney, other), status (extracerebral disease status; not controlled, controlled), and neuro (neurological symptoms; no, yes). To analyze the competing risk end point, leptomeningeal dissemination, we used cause-specific proportional hazard models, which are identical to usual Cox regression models [11].
The descriptive statistics for the study data are shown in Table I. The data have heavy censoring, and the number of events differs considerably for the primary tumor categories. In particular, the kidney cancer group has no events. Further, as we illustrate below, monotone likelihood was observed in these data because of the primary tumor categories, while the parameter estimate of the kidney cancer group converges to âˆ’âˆž.
Next, we consider the model selection based on AICâˆ—, the results of which are shown in Table II. The full model, which includes all the covariates, was selected by AICâˆ— as the best. In the best model, the hazard ratios were estimated by using Firthâ€™s penalized partial likelihood approach (Table III). To illustrate the problem of monotone likelihood, the hazard ratios estimated by using a usual Cox regression model are also shown. For the usual Cox regression model, when monotone likelihood occurred, the hazard ratio of the kidney cancer group was 0.00 (= exp(âˆ’âˆž)), standard error was 543.30, p-value of the Wald test was 0.98, and p-value of the likelihood ratio test was <0.01. Although the number of events for lung cancer was considerably larger than that for kidney cancer (Table I), a large p-value was observed in the Wald test. On the contrary, the results derived by using Firthâ€™s penalized partial likelihood approach were plausible. The hazard ratio was 0.12, and standard error was 1.43 (Table III); therefore, usual Cox regression models were unsatisfactory in the presence of monotone likelihood.
Now, we return to the model selection result based on AICâˆ— when using Firthâ€™s penalized partial likelihood approach. As shown in Table II, model selection based on AICâˆ— tends to select models that have many parameters, and to support this statement, we discuss the theoretical property of AICâˆ— in Section 3.3. In Table III, the best model under AICâˆ— includes variables that have considerably small effects such as age (HR = 1.00, p-value = 0.98) and status (HR = 1.03, p-value = 0.89), whose p-values were very large. Although these variables have little association with the time-to-event, such variables were included in the best model and subsequent models ranked in the top 5. Indeed, because model selection based on AICâˆ— performs badly, we propose an alternative approach herein to address this problem.

3423

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

Table I. Number of events (leptomeningeal dissemination) and censored values for the study data (n = 1073).

Covariate

Group

Event Censored % Censored

age

<65

69

393

â‰¥65

76

535

sex

Female

62

370

Male

83

558

kps

â‰¥80

132

810

â‰¤70

13

118

ntumor

1

49

365

2â€“4

61

412

5â€“10

35

151

diameter

<1.6 cm

76

455

â‰¥1.6 cm

69

473

volume

<1.9 mL

75

459

â‰¥1.9 mL

70

469

ptumor

Lung

116

705

Breast

17

95

Gastrointestinal

9

66

Kidney

0

32

Other

3

30

status

Not controlled 103

634

Controlled

42

294

neuro

No

105

656

Yes

40

272

Total

145

928

85.1 87.6 85.6 87.1 86.0 90.1 88.2 87.1 81.2 85.7 87.3 86.0 87.0 85.9 84.8 88.0 100.0 90.9 86.0 87.5 86.2 87.2 86.5

Note: ntumor, number of tumors; kps, Karnofsky performance status; diameter, maximum diameter of largest tumor; volume, cumulative tumor volume; ptumor, primary tumor category; status, extracerebral disease status; neuro, neurological symptoms.

Table II. The top five models based on AICâˆ— for the study data. Model

AICâˆ—

age sex kps ntumor diameter volume ptumor status neuro 1731.50

age sex

ntumor diameter volume ptumor status neuro 1731.80

age sex kps ntumor diameter

ptumor status neuro 1731.85

age sex kps ntumor

volume ptumor status neuro 1731.85

age sex

ntumor

volume ptumor status neuro 1732.16

Note: ntumor, number of tumors; kps, Karnofsky performance status; diameter, maximum diameter of largest tumor; volume, cumulative tumor volume; ptumor, primary tumor category; status, extracerebral disease status; neuro, neurological symptoms; AIC, Akaikeâ€™s information criterion.

3. Infomation criteria for Firthâ€™s penalized partial likelihood approach
3.1. Cox regression model
We consider Cox regression models [1] with Andersen and Gillâ€™s [12] counting process formulation. A triplet (Î©, F, P) is a probability space, and {Ft, t âˆˆ [0, 1]} is an increasing right continuous family of sub ðœŽ-algebras of F that includes failure time and covariate histories to scaled time t and censoring histories to t+. Let ð = (N1, â€¦ , Ni, â€¦ , Nn)T for i = 1, â€¦ , n be an n-component multivariate counting process, where Ni(t) counts the number of failures (0 or 1) for the ith individual in scaled time t âˆˆ [0, 1]. The sample paths N1, â€¦ , Ni, â€¦ , Nn are step functions, with 0 at time 0 and no two components having simultaneous jumps. Now, suppose that Ni(t) has a random intensity process hi(t) = Yi(t)h0(t) exp{ðœ·T0 ð™i(t)}, where h0(t) is a baseline hazard function, Yi(t) is a predictable process taking the value of 1 if the ith individual is at risk at time t and 0 otherwise, ðœ·0 = (ð›½01, â€¦ , ð›½0p)T is a p-dimensional vector of the true regression parameters, and the p-dimensional vector ð™i = (Zi1, â€¦ , Zip)T is the predictable covariate process for the

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

3424

K. NAGASHIMA AND Y. SATO

Table III. Parameter estimates of the best model based on AICâˆ— for the study data.

Covariate

Usual Cox

Firthâ€™s penalized partial

regression model

likelihood approach

HR SE 95% CI p (Wald) p (LR) HR SE 95% CI p (LR)

age (â‰¥65 vs. <65)

1.01 0.17 0.72 1.40 0.98

sex (male vs. female) 1.20 0.19 0.83 1.73 0.34

ntumor

1 vs. 2â€“4

0.72 0.20 0.49 1.06 0.09

5â€“10 vs. 2â€“4

1.58 0.22 1.03 2.41 0.04

kps (â‰¥80 vs. <70)

1.04 0.32 0.55 1.96 0.90

diameter (â‰¥1.6 vs. <1.6) 0.90 0.33 0.47 1.69 0.73

volume (â‰¥1.9 vs. <1.9) 1.10 0.32 0.59 2.08 0.76

ptumor

Breast vs. lung

1.03 0.29 0.58 1.83 0.91

GI vs. lung

1.55 0.37 0.75 3.21 0.24

Kidney vs. lung

0.00 543.30 0.00 â€“ 0.98

Others vs. lung

0.77 0.59 0.24 2.45 0.66

status (nc. vs. controlled) 1.02 0.19 0.71 1.47 0.92

neuro (yes vs. no)

1.50 0.23 0.96 2.36 0.07

0.98 1.00 0.17 0.72 1.40 0.98 0.33 1.19 0.19 0.83 1.72 0.34
0.09 0.72 0.20 0.49 1.06 0.09 0.04 1.59 0.22 1.04 2.43 0.04 0.90 1.07 0.32 0.57 2.00 0.83 0.73 0.90 0.33 0.47 1.70 0.74 0.76 1.11 0.32 0.59 2.08 0.76
0.91 1.05 0.29 0.60 1.87 0.85 0.26 1.61 0.37 0.79 3.31 0.21 <0.01 0.12 1.43 0.01 1.91 0.02 0.64 0.89 0.55 0.30 2.63 0.83 0.92 1.03 0.19 0.71 1.48 0.89 0.08 1.51 0.23 0.97 2.37 0.07

Note: HR, hazard ratio; kps, Karnofsky performance status; ntumor, number of tumors; diameter, maximum diameter of largest tumor; volume, cumulative tumor volume; ptumor, primary tumor category; status, extracerebral disease status; neuro, neurological symptoms; GI, gastrointestinal; nc., not controlled; LR, likelihood ratio; SE, standard error.

ith individual. Note that the superscript â€˜Tâ€™ indicates the transpose of a matrix or a vector. We assume

tâˆ«h0taht i((Nx)i,dYxi

, ð™i) are independent and identically distributed. In are independent local square integrable martingales

this case, the on the scaled

processes Mi(t) time interval [0,

= Ni(t) âˆ’ 1]. Ni, Yi,

and ð™i are assumed to be adapted to {Ft, t âˆˆ [0, 1]}.

Under these settings, the log-partial likelihood function is defined as

l(ð,

ð˜,

ð™;

ðœ·)

=

âˆ‘n
i=1

âˆ«0

1
ðœ· T ð™i (x)

âˆ’

log

{nS(0) (ðœ· ,

} x)

dNi(x),

the score function is defined as

ð”(ðœ· )

=

ðœ•l(ð, ð˜, ð™; ðœ·) ðœ•ðœ·

=

âˆ‘n i=1 âˆ«0

1

{ ð™i(x)

âˆ’

ð’(1)(ðœ·, x) } S(0)(ðœ·, x)

dNi(x),

and the observed information matrix is defined as

ðˆ(ðœ·)

=

ðœ•2l(ð, ð˜, ð™; ðœ·) ðœ•ðœ·ðœ•ðœ·T

=

âˆ‘n i=1 âˆ«0

1

[ ð’(2)(ðœ·, x) S(0)(ðœ·, x)

âˆ’

{ ð’(1)(ðœ·, x) }âŠ—2] S(0)(ðœ·, x)

dNi(x),

where ð˜ = (Y1, â€¦ , matrix function ð’(2) for a vector ð›, ð›âŠ—0

=aYrne)1Td,,eð›ð™fiâŠ—n1=ed=(að™sð›1,ð’, (â€¦akn)(dðœ·, ð™ð›, tnâŠ—))2T=,=tnhâˆ’eð›1ð›sâˆ‘cTa.nil=Ba1ryYfiuu(nst)icð™ntgiio(tnt)hâŠ—iSsk(0en)x,opttha{teðœ·ioTvnð™e,ci(tttho)er}

function ð’(1), and the for k = 0, 1, 2. Here,
usual Cox regression

estimator ðœ·Ì‚ Cox is obtained by solving ð”(ðœ·) = ðŸŽ.

3.2. Firthâ€™s bias correction method for Cox regression models
Heinze and Schemper [3] directly applied Firthâ€™s bias correction method [4] to Cox regression models to overcome monotone likelihood. They proposed an estimation method based on the penalized log-partial likelihood, lâˆ—(ð, ð˜, ð™; ðœ·) = l(ð, ð˜, ð™; ðœ·)+0.5 log |ðˆ(ðœ·)|, and the modified score function ð”âˆ—(ðœ·) = ð”(ðœ·)+ ðš(ðœ·), where |ðˆ(ðœ·)| is the determinant of the observed information matrix, ðš(ðœ·) = {a1(ðœ·), â€¦ , ap(ðœ·)}T are modification terms, and aj(ðœ·) = tr [{ðˆ(ðœ·)}âˆ’1{ðœ•ðˆ(ðœ·)âˆ•ðœ•ð›½j}]âˆ•2. The penalized partial likelihood estimator ðœ·Ì‚ is obtained by solving ð”âˆ—(ðœ·) = ðŸŽ, which is different from the usual Cox regression estimator, ðœ·Ì‚ Cox. They

3425

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

only assessed the empirical performance of these methods by using simulation studies. These simulation
results confirm the satisfactory performance of the penalized likelihood ratio test and profile penalized
likelihood confidence interval under monotone likelihood. The modification term ðš(ðœ·) can be derived by using an asymptotic expansion of E[ð”âˆ—(ðœ·)]. It
will be convenient to employ the notation of Cox and Snell [13] and Firth [4]. Let Uj(ðœ·) = ðœ•l(ð, ð˜, ð™; ðœ·)âˆ•ðœ•ð›½j, Ujk(ðœ·) = ðœ•2l(ð, ð˜, ð™; ðœ·)âˆ•ðœ•ð›½jðœ•ð›½k, Ujkl(ðœ·) = ðœ•3l(ð, ð˜, ð™; ðœ·)âˆ• ðœ•ð›½jðœ•ð›½kðœ•ð›½l, the null cumulants are ðœ…j,k = nâˆ’1E[Uj(ðœ·0)Uk(ðœ·0)], ðœ…jk = nâˆ’1E[Ujk(ðœ·0)], ðœ…j,kl = nâˆ’1E[Uj(ðœ·0)Ukl(ðœ·0)], ðœ…j,k,l = nâˆ’1E[Uj(ðœ·0)Uk(ðœ·0)Ul(ðœ·0)], and ðœ…jkl = nâˆ’1E[Ujkl(ðœ·0)]. Based on the asymptotic expansion, the bias of the estimator of the mth regression parameter is given by

E[nâˆ’1âˆ•2(ð›½Ì‚m

âˆ’

ð›½0m)]

=

nâˆ’1 ðœ… l,j

{ âˆ’

1

2

ðœ… k,l (ðœ…j,k,l

+

ðœ…j,kl)

+

} ð›¼j (ðœ· 0 )

+

O(nâˆ’3âˆ•2),

(1)

where ðœ…k,l denotes the inverse of the Fisher information matrix, Einstein summation convention is applied, and ð›¼j(ðœ·0) = E[aj(ðœ·0)]. From Eq. 1, if ð›¼j(ðœ·0) = ðœ…k,l(ðœ…j,k,l + ðœ…j,kl)âˆ•2, then the first-order bias term disappears. Moreover, if ðœ…j,k + ðœ…jk = 0, ðœ…j,k,l + ðœ…j,kl + ðœ…k,jl + ðœ…l,jk + ðœ…jkl = 0, and ðœ…j,kl = 0, then

ð›¼j (ðœ· )

=

1 2

ðœ… k,l

(ðœ…j,k,l

+ ðœ…j,kl)

=

1 2

ðœ…

k,lðœ…j,k,l

=

âˆ’

1 2

ðœ…

k,lðœ…jkl.

From the aforementioned result and paying attention to the summation convention, the modification term

can be written as

aj (ðœ· )

=

1 2

tr

[{ðˆ(ðœ· )}âˆ’1 {ðœ• ðˆ(ðœ· )âˆ•ðœ• ð›½j }].

However, the relationships ðœ…j,k,l + ðœ…j,kl + ðœ…k,jl + ðœ…l,jk + ðœ…jkl = 0 and ðœ…j,kl = 0 are a nontrivial result in Cox regression models, and thus, they have never been evaluated. Nevertheless, we proved that these relation-
ships are true in Cox regression models under independent and identically distributed (see Appendix A
for more details).

3.3. Problem in heuristic information criteria
As noted earlier, although model selection is an important issue in data analysis, the model selection criteria for the penalized partial likelihood approach have never been studied. To our best knowledge, only the SAS PHREG procedure can be used to obtain an AIC-type heuristic information criterion, AIC âˆ— = âˆ’2lâˆ—(ð, ð˜, ð™; ðœ·Ì‚ ) + 2p = âˆ’2l(ð, ð˜, ð™; ðœ·Ì‚ ) + 2p âˆ’ log |ðˆ(ðœ·Ì‚ )|. Moreover, other major statistical software (e.g., Stata and R) can only output the penalized log-partial likelihood. However, AICâˆ— is not theoretically justified.
Now, we discuss a property of AICâˆ—. After some algebra,
AIC âˆ— = âˆ’2l(ð, ð˜, ð™; ðœ·Ì‚ ) + (2 âˆ’ log n)p âˆ’ log{nâˆ’p|ðˆ(ðœ·Ì‚ )|}.

The

last

term

on

the

right-hand

side

âˆ’ log{nâˆ’p|ðˆ(ðœ·Ì‚ )|}

converges

to

a

constant

because

nâˆ’1ðˆ(ðœ·Ì‚ )

P
âˆ’â†’

ðšº(ðœ· 0 )

(see

Appendix

B

for

more

details)

and

|nâˆ’1ðˆ(ðœ·Ì‚ )|

=

nâˆ’p|ðˆ(ðœ·Ì‚ )|

P
âˆ’â†’

|ðšº(ðœ· 0 )|

as

n

â†’

âˆž,

where

ðšº(ðœ·0) = âˆ«01 ð¯(ðœ·0, x)s(0)(ðœ·0, x)h0(x) dx, ð¯ = (ð¬(2)âˆ•s(0)) âˆ’ {ð¬(1)âˆ•s(0)}âŠ—2, s(0)(ðœ·, t) = E[S(0)(ðœ·, t)], ð¬(1)(ðœ·, t) =

E[ð’(1)(ðœ·, t)], and ð¬(2)(ðœ·, t) = E[ð’(2)(ðœ·, t)]. If n â‰¥ 8, then 2 âˆ’ log n is negative. Because AICâˆ— includes the

term (2 âˆ’ log n)p, this criterion tends to select models with large p as n â†’ âˆž. Importantly, this result

indicates that AICâˆ— does not avoid over-fitting.

Similarly, the SAS PHREG procedure implements a BIC-type heuristic information criterion, BIC âˆ— = âˆ’2lâˆ—(ð, ð˜, ð™; ðœ·Ì‚ )+p log d, where d is the number of events [14]. Let c = 1âˆ’dâˆ•n âˆˆ (0, 1] be the proportion of censoring, BIC âˆ— = âˆ’2l(ð, ð˜, ð™; ðœ·Ì‚ ) + p log(1 âˆ’ c) âˆ’ log{nâˆ’p|ðˆ(ðœ·Ì‚ )|}. Because log(1 âˆ’ c) < 0, BICâˆ— has

a negative penalty term in proportion to the number of regression parameters.

3.4. Proposed criteria
As an alternative approach to address the issue discussed in Section 3.3, we propose a criterion termed herein AIC for Firthâ€™s penalized partial likelihood approach (AICF). AIC is a model selection criterion used to measure the goodness of fit of a model by using the risk function based on Kullbackâ€“Leibler

3426

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

(KL) information between the true model and the candidate model, which is a measure of discrepancy

from the true model.

Xu et al. [15] provided a theoretical justification for the use of partial likelihood in AIC under

usual Cox regression models, which was also extended to proportional hazards mixed models. These

authors developed a profile AIC [16] for selecting a model with minimum KL information based

on the profile likelihood under Cox regression models. It is well known that partial likelihood can

be considered as profile likelihood [17â€“19]. Suppose that f denotes the true distribution and gðœ·,ð€ = g(â‹…; ðœ·, ð€) denotes candidate models, where ð€ âˆˆ ðš² is the nuisance parameter and ðš² is the param-

eter space of ð€. The KL information can be written as KL( f , gðœ·,ð€) = E(N,Y,ð™)âˆ¼f [log f (N, Y, ð™) âˆ’ log gðœ·,ð€(N, Y, ð™)]. Here and subsequently, we write EN = E(N,Y,ð™)âˆ¼f for convenience. Focusing on the regression parameters ðœ· alone and ignoring the constant term EN[log f (N, Y, ð™)] in KL, the minimum KL information is given at ðœ·0 such that EN[log gðœ·0 (N, Y, ð™)] = maxðœ· EN[log gðœ· (N, Y, ð™)], where EN[log gðœ· (N, Y, ð™)] = maxð€ EN[log gðœ·,ð€(N, Y, ð™)]. If the model is correctly specified (i.e., f = gðœ·0 ), cE2tiapoNn,n[la,bosEegaNwgnEðœ·raNi0Ìƒtp([tNeâˆ’pnr,2oYalx(s,ðiÌƒð™mm,)að˜a]Ìƒtxe,=ð€ð™lÌƒyâˆ‘;âˆ«uðœ·Î©Ì‚nin=Clb1ooixgga)ðœ·]sge(bðœ·Nda0i(se,NesYdt,ii,Ymoð™,naið™;ttoh)ðœ·red,oPð€lof.)gtU=hpenrldo(rðiefsirlk,eð˜Cfluo,ikð™nxec;lrtiðœ·eihog)on.roe,Xsdwsu,ihaoeennrtdeamp(l.orðÌƒo[d,1feið˜5Ìƒlles],,ð™AsÌƒthh)IoCeiws,loeaâˆ’dgf2utlpht(ruðaÌƒort,feitð˜lhÌƒoee,bð™lÌƒsriiek;sreðœ·kÌ‚vlCiafhotuixono)ocn+d-.

Based on Akaike [8], the minimum risk function corresponds to the minimum KL information using a

future observation.

Therefore, we consider a partial likelihood-based risk function, RISK = ENENÌƒ [âˆ’2l(ðÌƒ , ð˜Ìƒ , ð™Ìƒ ; ðœ·Ì‚ )], and

derive AICF as an approximately unbiased estimator of RISK. In the definition of RISK, the estimator

ðœ·Ì‚ was not the usual estimator. When we

Cox regression estimator simply estimate RISK by

ðœ·Ì‚âˆ’C2olx(,ðb,uð˜t ,rð™at;hðœ·Ì‚e)r,

the we

Firthâ€™s penalized partial need to correct bias B.

likelihood Here, B is

defined as

B = ENENÌƒ [2l(ð, ð˜, ð™; ðœ·Ì‚ ) âˆ’ 2l(ðÌƒ , ð˜Ìƒ , ð™Ìƒ ; ðœ·Ì‚ )]

= b1 + b2 + b3,

where

b1 = EN[ENÌƒ [2l(ðÌƒ , ð˜Ìƒ , ð™Ìƒ ; ðœ·0)] âˆ’ ENÌƒ [2l(ðÌƒ , ð˜Ìƒ , ð™Ìƒ ; ðœ·Ì‚ )]], b2 = EN[2l(ð, ð˜, ð™; ðœ·0)] âˆ’ ENÌƒ [2l(ðÌƒ , ð˜Ìƒ , ð™Ìƒ ; ðœ·0)],

and b3 = EN[2l(ð, ð˜, ð™; ðœ·Ì‚ ) âˆ’ 2l(ð, ð˜, ð™; ðœ·0)].

According to this definition, B includes A second-order Taylor expansion of ENÌƒ

the true [l(ðÌƒ , ð˜Ìƒ ,

parameter vector ðœ· ð™Ìƒ ; ðœ·Ì‚ )] around ðœ·Ì‚ =

0. Therefore, ðœ·0 gives

we

need

approximate

B.

ENÌƒ [l(ðÌƒ , ð˜Ìƒ ,

ð™Ìƒ ;

ðœ·Ì‚ )]

â‰ˆ

ENÌƒ [l(ðÌƒ ,

ð˜Ìƒ , ð™Ìƒ ;

ðœ· 0 )]

âˆ’

1 {âˆšn(ðœ·Ì‚ 2

âˆ’

ðœ· 0 )T }ðšº(ðœ· 0 ){âˆšn(ðœ·Ì‚

âˆ’

ðœ· 0 )},

(2)

a first-order Taylor expansion of ð”âˆ—(ðœ·Ì‚ ) = ðŸŽ around ðœ·Ì‚ = ðœ·0 gives

âˆšn(ðœ·Ì‚ âˆ’ ðœ·0) â‰ˆ {nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1{nâˆ’1âˆ•2ð”âˆ—(ðœ·0)},

(3)

and a second-order Taylor expansion of l(ð, ð˜, ð™; ðœ·0) around ðœ·0 = ðœ·Ì‚ gives

l(ð,

ð˜,

ð™; ðœ·0)

â‰ˆ

l(ð,

ð˜,

ð™;

ðœ·Ì‚ )

âˆ’

1 {âˆšn(ðœ·Ì‚ 2

âˆ’

ðœ·0)T}{nâˆ’1ðˆ(ðœ·Ì‚ )}{âˆšn(ðœ·Ì‚

âˆ’

ðœ· 0 )}

+

{ðš(ðœ·Ì‚ )}T(ðœ·Ì‚

âˆ’

ðœ· 0 ),

(4)

where ðˆâˆ—(ðœ·) = âˆ’ðœ•ð”âˆ—(ðœ·)âˆ•ðœ•ðœ·T = ðˆ(ðœ·) âˆ’ ðœ•ðš(ðœ·)âˆ•ðœ•ðœ·T. From the fact E[ f (ðƒ)] = E[ tr {f (ðƒ)}] for a scalar function f and a random vector ðƒ, and by substituting Eqs 2-4 into b1, we can show that

b1 â‰ˆ EN [ tr {ðšº(ðœ·0){nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1{nâˆ’1ð‰âˆ—(ðœ·0)}{nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1}], where ð‰âˆ—(ðœ·) = âˆ‘ni=1{ð‹âˆ—i (ðœ·)}âŠ—2, ð‹âˆ—i (ðœ·) = ð‹i(ðœ·) âˆ’ ðš(ðœ·)âˆ•n, and ð‹i(ðœ·0) = âˆ«01{ð™i(x) âˆ’ ð’(1)(ðœ·0, x)âˆ•S(0)(ðœ·0, x)} dMi(x). Similarly,

b3 â‰ˆ EN[ tr {{nâˆ’1ðˆ(ðœ·Ì‚ )}{nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1{nâˆ’1ð‰âˆ—(ðœ·0)}{nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1 âˆ’ 2{ðš(ðœ·Ì‚ )}T(ðœ·Ì‚ âˆ’ ðœ·0)}].

3427

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

Under

the

true

model

nâˆ’1 ð‰âˆ— (ðœ· 0 )

P
âˆ’â†’

ðšº(ðœ· 0 ),

nâˆ’1 ðˆâˆ— (ðœ· 0 )

P
âˆ’â†’

ðšº(ðœ· 0 ),

nâˆ’1ðˆ(ðœ·Ì‚ )

P
âˆ’â†’

ðšº(ðœ· 0 ),

and

ðš(ðœ·Ì‚ )

=

Op(1)

(see Data S1 and Appendix B). Therefore, by applying the continuous mapping theorem, we obtain

tr {ðšº(ðœ·0){nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1{nâˆ’1ð‰âˆ—(ðœ·0)}{nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1}

P
âˆ’â†’

tr {ðšº(ðœ·0){ðšº(ðœ·0)}âˆ’1ðšº(ðœ·0){ðšº(ðœ·0)}âˆ’1} = p,

and

tr {{nâˆ’1ðˆ(ðœ·Ì‚ )}{nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1{nâˆ’1ð‰âˆ—(ðœ·0)}{nâˆ’1ðˆâˆ—(ðœ·0)}âˆ’1 âˆ’ 2{ðš(ðœ·Ì‚ )}T(ðœ·Ì‚ âˆ’ ðœ·0)}

P
âˆ’â†’

tr {ðšº(ðœ·0){ðšº(ðœ·0)}âˆ’1ðšº(ðœ·0){ðšº(ðœ·0)}âˆ’1} = p,

as n â†’ âˆž. Moreover, it is obvious that b2 = 0. Further details are presented in Data S1. Hence, b1 â‰ˆ p, b3 â‰ˆ p, and bias B = b1 + b2 + b3 can be approximated by 2p. From the aforementioned results, we define AICF as
AICF = âˆ’2l(ð, ð˜, ð™; ðœ·Ì‚ ) + 2p.

The AICF does not include the penalty term of AICâˆ—, 0.5 log |ðˆ(ðœ·Ì‚ )|. Even in the penalized partial likelihood setting, non-penalized likelihood should be used for risk estimation. Sometimes, penalty terms for parameter estimation have a strong effect on a model selection criterion.
Similarly, based on the results of a previous study [14], we propose BIC for Firthâ€™s penalized partial likelihood approach
BICF = âˆ’2l(ð, ð˜, ð™; ðœ·Ì‚ ) + p log d.

The detailed derivation is omitted, but is similar to that described previously [14]. Note that SAS and R programs for AICF and BICF are provided in Data S3.

4. Simulation

4.1. Simulation conditions

Simulation studies were conducted to investigate the performance of model selection critera (AICF, BICF,

AICâˆ—, and BICâˆ—) in a monotone likelihood setting and to check that the property of AICâˆ— discussed in

Section 3.3 holds. We set the simulation conditions by referring to [3] and the generated observations

{Ni, Yi, ð™i}

from

exponential

distributions

with

hazard

functions

hi(t)

=

h0(t)ð›¾i(t)

=

h0

(t)

exp{ðœ·

T 0

ð™i

},

where h0(t) = 1, ðœ·0 = (log ðœƒ, log ðœƒ, log ðœƒ, 0, 0)T, ð™i = (Zi1, Zi2, Zi3, Zi4, Zi5)T, and Zij âˆ¼ Bernoulli (q). We

further set the proportion of covariates as q = 0.5 or 0.8, the regression parameters as ðœƒ = 1.3, 2, 4, or 16,

the proportion of censoring as c = 0, 50, or 90 (%), and the total sample size as n = 100, 200, or 1000.

We generated data under simple type I censoring; the observations of each individual were censored

at a suitable time ðœ for each simulation. Time ðœ was determined to achieve an expected 50% and 90%

censoring. We find monotone likelihood in situations of high censoring and high parameter values. For

each data configuration, we generated R = 20, 000 simulations. For each simulation, we calculated AICF,

AICâˆ—, BICF, and BICâˆ— for the following 11 models:

Model 1: log ð›¾i(t) = ð›½1Zi1 Model 2: log ð›¾i(t) = ð›½4Zi4 Model 3: log ð›¾i(t) = ð›½1Zi1 + ð›½2Zi2 Model 4: log ð›¾i(t) = ð›½1Zi1 + ð›½4Zi4 Model 5: log ð›¾i(t) = ð›½4Zi4 + ð›½5Zi5 Model 6: log ð›¾i(t) = ð›½1Zi1 + ð›½2Zi2 + ð›½3Zi3 (the true model) Model 7: log ð›¾i(t) = ð›½1Zi1 + ð›½2Zi2 + ð›½4Zi4 Model 8: log ð›¾i(t) = ð›½1Zi1 + ð›½4Zi4 + ð›½5Zi5 Model 9: log ð›¾i(t) = ð›½1Zi1 + ð›½2Zi2 + ð›½3Zi3 + ð›½4Zi4 Model 10: log ð›¾i(t) = ð›½1Zi1 + ð›½2Zi2 + ð›½4Zi4 + ð›½5Zi5 Model 11: log ð›¾i(t) = ð›½1Zi1 + ð›½2Zi2 + ð›½3Zi3 + ð›½4Zi4 + ð›½5Zi5 (the full model)

3428

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

Model 6 is the true model, and Model 11 is the full model, that is, the model with maximum p.
Because it is well known that AIC is designed for optimal prediction and BIC is designed to identify the true model, we assessed the predictive performance of AICF and AICâˆ—. We evaluated the mean of the
difference between the estimated mean risk (MR) and value of the information criterion in each model
and its 5 and 95 percentiles, as well as the estimated MR for the selected model based on new data. The MR and its estimator, MÌ‚R, are defined as

MR

=

1 R

âˆ‘R
r=1

ENÌƒ

[âˆ’2l(ðÌƒ ,

ð˜Ìƒ ,

ð™Ìƒ ;

ðœ·Ì‚

r

] )

and

[

{

}]

MÌ‚R

=

âˆ’2 R

âˆ‘R
r=1

âˆ‘n
i=1

âˆ«0

1

ðœ·Ì‚

T r

ð™Ìƒ ri

(x)

âˆ’

log

âˆ‘n

YÌƒ rj (x)

exp{ðœ·Ì‚

T r

ð™Ìƒ rj(x)}

j=1

dNÌƒ ri(x),

where (ðÌƒ , ð˜Ìƒ , ð™Ìƒ ) is another dataset of the same size, ðœ·Ì‚ r is the model estimate of each replication, and ð™ri
is the covariate vector in each model and replication. The absolute value of the mean difference between the MÌ‚R and the value of the information criterion should be small because AIC is an estimator of risk

function; thus, the mean difference can be regarded as an empirical bias of an AIC-type criterion. The estimated MR for the selected model, MÌ‚Rsel, is defined as

[

{

}]

MÌ‚Rsel

=

âˆ’2 R

âˆ‘R
r=1

âˆ‘n i=1 âˆ«0

1

ðœ·Ì‚

T r,sel

ð™Ìƒ ri(x)

âˆ’

log

âˆ‘n

YÌƒ rj

(x)

exp{ðœ·Ì‚

T r,sel

ð™Ìƒ rj(x)}

j=1

dNÌƒ ri(x),

where ðœ·Ì‚ r,sel is an estimate of the selected model. The MÌ‚Rsel should be small and is considered to be a performance indicator for prediction, as it measures the goodness of fit for the selected model to a future

data as a mean deviance.

m

To =

assess 1, 2, â€¦

the , 11.

performance We estimate

of the

the criteria, we model selection

evaluated model selection probability by PÌ‚ m = {# of

probability Pm, where the model m selected}âˆ•

{# of replication (R = 20, 000)}, the relative frequency of the model obtained by minimizing the infor-

mation criterion.

4.2. Simulation results
The mean of the difference between the estimated MR and value of information criterion and its 5 and 95 percentiles for Models 6 and 11 for q = 0.5 is shown in Table IV. The mean differences for AICF were smaller than those for AICâˆ— under all conditions. The mean differences for AICâˆ— increased with the
number of events. The 5 and 95 percentiles for AICF were approximately symmetric around 0, whereas the percentiles for AICâˆ— were not symmetric. For instance, in the case with c = 0%, ðœƒ = 1, n = 100, and Model 6 (true model), the mean difference and its percentiles for AICF and AICâˆ— were âˆ’0.4 (âˆ’9.9, 5.9) and âˆ’9.8 (âˆ’19.2, âˆ’3.5); in the case with c = 0%, ðœƒ = 1, n = 100, and Model 11 (full model), the mean difference and its percentiles for AICF and AICâˆ— were âˆ’1.1 (âˆ’11.2, 6.0) and âˆ’16.7 (âˆ’26.7, âˆ’9.7). Thus, AICâˆ— is clearly biased downward, as AICâˆ— includes unnecessary negative terms (Section 3.3). Larger bias
was observed in models with large p-values. Therefore, these models cannot estimate the risk function. The estimated MR for the selected model based on another new dataset, MÌ‚Rsel, for q = 0.5 is shown in Table IV. The MÌ‚Rsel for AICF was smaller than that for AICâˆ—, except in a case with c = 50%, ðœƒ = 4, and n = 1000, and c = 0%, ðœƒ = 1, and n = 200. Thus, the model selection based on AICF showed small
deviance for future data. These results revealed that AICF shows better prediction performance. The selection probability of Models 6 (the true model) and 11 (the full model) for AICF and AICâˆ—
when q = 0.5 is shown in Table V. For larger parameter values, larger sample sizes, and less censoring, the selection probability of the true model is larger for AICF than for AICâˆ—. For smaller parameter values, smaller sample sizes, and more censoring, the selection probability of the true model is larger for AICâˆ— than for AICF. The selection probability of the full model for AICF is smaller than that for AICâˆ—. On the contrary, the selection probability of the full model for AICâˆ— increases with the number of events. In particular, for n = 1000, the selection probability of the full model for AICâˆ— is equal to one because of the term (2 âˆ’ log n)p in AICâˆ—, as discussed in Section 3.3.

3429

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

3430

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Table IV. The mean of the difference between the estimated MR and the value of the information criterion in each model and its 5 and 95 percentiles, and the estimated MR for the selected model (the proportion of covariates: q = 0.5; the number of simulations: R = 20, 000).

c (%) ðœƒ n

Mean difference (5 percentile, 95 percentile)

Model 6 (true model)

Model 11 (full model)

AICF

AICâˆ—

AICF

AICâˆ—

MÌ‚Rsel

AICF

AICâˆ—

90

1 100 âˆ’0.4 ( âˆ’43.9, 45.9) âˆ’2.7 ( âˆ’44.2, 42.1) âˆ’1.1 ( âˆ’44.4, 45.5) âˆ’4.8 ( âˆ’44.7, 39.2)

94.38

95.05

90

1 200 0.1 ( âˆ’71.4, 74.6) âˆ’4.4 ( âˆ’74.8, 68.9) âˆ’0.1 ( âˆ’71.6, 74.9) âˆ’7.7 ( âˆ’77.1, 65.5) 212.87 214.55

90

1 1000 1.6 (âˆ’206.1, 218.1) âˆ’8.0 (âˆ’215.2, 208.0) 1.6 (âˆ’206.9, 218.2) âˆ’14.4 (âˆ’222.1, 201.4) 1373.64 1375.61

90

2 100 âˆ’0.4 ( âˆ’43.8, 45.8) âˆ’2.7 ( âˆ’44.1, 42.0) âˆ’1.0 ( âˆ’44.2, 45.6) âˆ’4.7 ( âˆ’44.6, 39.3)

94.40

95.04

90

2 200 âˆ’0.6 ( âˆ’72.0, 74.4) âˆ’5.2 ( âˆ’75.4, 68.8) âˆ’0.9 ( âˆ’72.4, 74.6) âˆ’8.5 ( âˆ’77.8, 65.2) 212.82 214.48

90

2 1000 1.3 (âˆ’205.9, 217.1) âˆ’8.3 (âˆ’215.1, 207.0) 1.3 (âˆ’206.6, 217.4) âˆ’14.8 (âˆ’221.8, 200.6) 1375.21 1377.21

90

4 100 âˆ’0.7 ( âˆ’44.2, 45.7) âˆ’3.0 ( âˆ’44.5, 41.9) âˆ’1.4 ( âˆ’44.6, 45.4) âˆ’5.1 ( âˆ’45.0, 39.1)

94.73

95.36

90

4 200 0.0 ( âˆ’71.6, 74.2) âˆ’4.6 ( âˆ’74.9, 68.6) âˆ’0.3 ( âˆ’71.5, 74.3) âˆ’7.9 ( âˆ’77.1, 65.0) 212.88 214.50

90

4 1000 âˆ’1.8 (âˆ’216.9, 214.8) âˆ’11.4 (âˆ’226.1, 204.7) âˆ’1.9 (âˆ’215.8, 213.4) âˆ’17.9 (âˆ’231.0, 196.7) 1376.07 1378.04

90 16 100 âˆ’0.7 ( âˆ’43.4, 45.9) âˆ’3.0 ( âˆ’43.8, 42.1) âˆ’1.4 ( âˆ’44.0, 45.2) âˆ’5.1 ( âˆ’44.4, 38.9)

94.49

95.15

90 16 200 âˆ’0.6 ( âˆ’71.3, 74.0) âˆ’5.2 ( âˆ’74.7, 68.3) âˆ’0.9 ( âˆ’71.5, 74.0) âˆ’8.5 ( âˆ’77.1, 64.6) 212.88 214.54

90 16 1000 0.1 (âˆ’207.5, 217.3) âˆ’9.5 (âˆ’216.6, 207.3) 0.1 (âˆ’207.6, 217.4) âˆ’15.9 (âˆ’222.8, 200.6) 1374.48 1376.42

50

1 100 0.1 ( âˆ’64.8, 62.8) âˆ’7.4 ( âˆ’71.8, 54.9) âˆ’0.4 ( âˆ’65.8, 62.3) âˆ’12.8 ( âˆ’77.4, 49.1) 432.37 434.56

50

1 200 âˆ’1.1 (âˆ’110.0, 104.1) âˆ’10.7 (âˆ’119.2, 94.2) âˆ’1.3 (âˆ’109.7, 104.7) âˆ’17.2 (âˆ’125.1, 88.2) 1000.80 1002.75

50

1 1000 3.0 (âˆ’322.5, 325.7) âˆ’11.5 (âˆ’336.8, 311.1) 2.9 (âˆ’322.5, 325.9) âˆ’21.2 (âˆ’346.3, 301.5) 6602.19 6603.65

50

2 100 âˆ’0.4 ( âˆ’64.5, 63.2) âˆ’7.8 ( âˆ’71.4, 55.2) âˆ’0.9 ( âˆ’65.6, 62.8) âˆ’13.3 ( âˆ’77.1, 49.7) 432.28 434.21

50

2 200 0.9 (âˆ’108.1, 107.4) âˆ’8.7 (âˆ’117.3, 97.4) 0.6 (âˆ’108.1, 106.9) âˆ’15.3 (âˆ’123.5, 90.4) 999.82 1001.35

50

2 1000 âˆ’2.9 (âˆ’322.7, 319.4) âˆ’17.4 (âˆ’337.0, 304.8) âˆ’3.0 (âˆ’322.5, 318.6) âˆ’27.1 (âˆ’346.4, 294.3) 6601.73 6601.85

50

4 100 âˆ’0.9 ( âˆ’66.0, 61.9) âˆ’8.4 ( âˆ’73.0, 54.0) âˆ’1.6 ( âˆ’66.9, 61.3) âˆ’14.0 ( âˆ’78.4, 48.2) 432.62 434.21

50

4 200 0.1 (âˆ’107.2, 104.3) âˆ’9.5 (âˆ’116.4, 94.4) âˆ’0.3 (âˆ’107.3, 103.9) âˆ’16.3 (âˆ’122.6, 87.4) 999.69 1000.66

50

4 1000 âˆ’3.0 (âˆ’323.1, 312.3) âˆ’17.4 (âˆ’337.4, 297.7) âˆ’3.2 (âˆ’323.1, 311.9) âˆ’27.3 (âˆ’347.0, 287.6) 6595.55 6595.42

50 16 100 0.1 ( âˆ’64.3, 63.4) âˆ’7.3 ( âˆ’71.2, 55.5) âˆ’0.7 ( âˆ’65.6, 62.4) âˆ’13.1 ( âˆ’77.0, 49.3) 431.82 433.14

50 16 200 âˆ’1.1 (âˆ’107.8, 104.4) âˆ’10.6 (âˆ’117.0, 94.5) âˆ’1.6 (âˆ’108.1, 104.4) âˆ’17.6 (âˆ’123.4, 87.9) 999.22 999.75

50 16 1000 0.8 (âˆ’320.5, 319.0) âˆ’13.7 (âˆ’334.8, 304.4) 0.5 (âˆ’321.0, 318.5) âˆ’23.6 (âˆ’344.8, 294.1) 6589.13 6589.34

0

1 100 âˆ’0.4 ( âˆ’9.9, 5.9) âˆ’9.8 ( âˆ’19.2, âˆ’3.5) âˆ’1.1 ( âˆ’11.2, 6.0) âˆ’16.7 ( âˆ’26.7, âˆ’9.7) 728.44 728.71

0

1 200 âˆ’0.1 ( âˆ’12.1, 8.8) âˆ’11.7 ( âˆ’23.7, âˆ’2.8) âˆ’0.5 ( âˆ’13.2, 9.0) âˆ’19.8 ( âˆ’32.4, âˆ’10.3) 1722.43 1722.27

0

1 1000 0.2 ( âˆ’23.8, 21.1) âˆ’16.2 ( âˆ’40.3, 4.6) 0.1 ( âˆ’24.3, 21.3) âˆ’27.4 ( âˆ’51.8, âˆ’6.3) 11779.42 11780.44

0

2 100 âˆ’0.5 ( âˆ’17.2, 14.1) âˆ’9.6 ( âˆ’26.2, 4.7) âˆ’1.2 ( âˆ’18.4, 13.8) âˆ’16.6 ( âˆ’33.6, âˆ’1.7) 705.35 706.37

0

2 200 âˆ’0.2 ( âˆ’23.6, 20.8) âˆ’11.6 ( âˆ’34.8, 9.3) âˆ’0.5 ( âˆ’23.9, 20.5) âˆ’19.5 ( âˆ’42.9, 1.4) 1675.67 1676.76

0

2 1000 0.4 ( âˆ’48.9, 48.0) âˆ’15.9 ( âˆ’65.2, 31.7) 0.3 ( âˆ’49.3, 48.2) âˆ’27.0 ( âˆ’76.6, 20.8) 11548.20 11549.24

0

4 100 âˆ’0.5 ( âˆ’24.1, 21.7) âˆ’9.2 ( âˆ’32.6, 12.8) âˆ’1.1 ( âˆ’24.9, 21.4) âˆ’16.0 ( âˆ’39.5, 6.2) 657.00 658.21

0

4 200 âˆ’0.5 ( âˆ’33.3, 30.8) âˆ’11.4 ( âˆ’44.1, 19.8) âˆ’0.9 ( âˆ’34.0, 30.7) âˆ’19.5 ( âˆ’52.4, 12.0) 1578.08 1579.22

0

4 1000 âˆ’0.4 ( âˆ’72.1, 69.9) âˆ’16.2 ( âˆ’87.8, 54.0) âˆ’0.4 ( âˆ’72.1, 69.9) âˆ’27.3 ( âˆ’98.8, 43.0) 11053.44 11054.48

0

16 100 âˆ’0.3 ( âˆ’26.8, 26.5) âˆ’7.9 ( âˆ’34.0, 18.4) âˆ’0.8 ( âˆ’27.7, 26.2) âˆ’14.6 ( âˆ’41.0, 12.0) 575.12 576.30

0

16 200 âˆ’0.1 ( âˆ’37.4, 37.8) âˆ’10.0 ( âˆ’47.0, 27.6) âˆ’0.4 ( âˆ’37.8, 37.6) âˆ’17.9 ( âˆ’55.1, 19.8) 1411.05 1412.15

0

16 1000 0.4 ( âˆ’81.5, 84.4) âˆ’14.4 ( âˆ’96.3, 69.4) 0.4 ( âˆ’82.0, 84.4) âˆ’25.5 (âˆ’107.8, 58.5) 10203.57 10204.62

MR, mean risk; Mean difference (5 percentile, 95 percentile), mean of the difference between the estimated mean risk, MÌ‚R, and the value of the

information criterion in each model and its 5 and 95 percentiles; MÌ‚Rsel, estimated MR for the selected model based on new data; c, proportion of random censoring; ðœƒ, regression parameters; n, total sample size. The values that are superior to other are highlighted.

K. NAGASHIMA AND Y. SATO

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

Table V. The selection probability (the proportion of covariates: q = 0.5; the number of simulations: R = 20, 000).

c (%) ðœƒ

n

Model 6 (true model)

Model 11 (full model)

AICF AICâˆ— BICF BICâˆ— AICF AICâˆ— BICF BICâˆ—

90

1.3 100 0.060 0.106 0.050 0.087 0.008 0.039 0.007 0.016

90

1.3 200 0.058 0.121 0.026 0.094 0.005 0.239 0.001 0.016

90

1.3 1000 0.059 0.000 0.005 0.094 0.005 1.000 0.000 0.019

90

2

100 0.063 0.110 0.052 0.092 0.008 0.041 0.007 0.019

90

2

200 0.060 0.116 0.024 0.093 0.005 0.238 0.001 0.018

90

2

1000 0.062 0.000 0.006 0.096 0.004 1.000 0.000 0.018

90

4

100 0.061 0.106 0.052 0.086 0.008 0.042 0.007 0.018

90

4

200 0.061 0.115 0.026 0.092 0.006 0.239 0.001 0.018

90

4

1000 0.055 0.000 0.005 0.090 0.005 1.000 0.000 0.019

90 16

100 0.062 0.110 0.052 0.091 0.008 0.043 0.006 0.018

90 16

200 0.058 0.119 0.023 0.093 0.006 0.234 0.001 0.017

90

16

1000 0.060 0.000 0.005 0.098 0.005 1.000 0.000 0.020

50

1.3 100 0.062 0.000 0.011 0.095 0.007 1.000 0.000 0.021

50

1.3 200 0.064 0.000 0.006 0.104 0.006 1.000 0.000 0.022

50

1.3 1000 0.091 0.000 0.003 0.135 0.007 1.000 0.000 0.027

50

2

100 0.082 0.000 0.018 0.122 0.010 1.000 0.000 0.027

50

2

200 0.099 0.000 0.015 0.140 0.010 1.000 0.000 0.031

50

2

1000 0.258 0.000 0.028 0.294 0.025 1.000 0.000 0.070

50

4

100 0.109 0.000 0.030 0.148 0.017 1.000 0.000 0.039

50

4

200 0.154 0.000 0.031 0.194 0.020 1.000 0.000 0.052

50

4

1000 0.469 0.000 0.142 0.462 0.053 1.000 0.000 0.116

50 16

100 0.133 0.000 0.044 0.172 0.022 1.000 0.002 0.050

50 16

200 0.203 0.000 0.054 0.242 0.029 1.000 0.001 0.066

50

16

1000 0.596 0.000 0.305 0.544 0.072 1.000 0.000 0.143

0

1.3 100 0.270 0.000 0.087 0.304 0.033 1.000 0.001 0.067

0

1.3 200 0.468 0.000 0.188 0.468 0.054 1.000 0.001 0.108

0

1.3 1000 0.778 0.000 0.919 0.658 0.085 1.000 0.001 0.155

0

2

100 0.745 0.000 0.820 0.662 0.091 1.000 0.007 0.145

0

2

200 0.778 0.000 0.968 0.670 0.086 1.000 0.003 0.150

0

2

1000 0.786 0.000 0.991 0.670 0.081 1.000 0.001 0.149

0

4

100 0.772 0.000 0.959 0.676 0.089 1.000 0.007 0.144

0

4

200 0.773 0.000 0.971 0.664 0.085 1.000 0.004 0.150

0

4

1000 0.786 0.000 0.990 0.670 0.081 1.000 0.001 0.149

0

16

100 0.774 0.000 0.958 0.690 0.088 1.000 0.007 0.137

0

16

200 0.779 0.000 0.974 0.679 0.085 1.000 0.003 0.144

0

16

1000 0.788 0.000 0.991 0.668 0.081 1.000 0.001 0.151

Note: c, proportion of random censoring; ðœƒ, regression parameters; n, total sample size. The values that are superior to other are highlighted.

The selection probability of Models 6 (true model) and 11 (full model) for BICF and BICâˆ— when q = 0.5 is shown in Table V. For larger parameter values, larger sample sizes, and less censoring, the selection probability of the true model was larger for BICF than for BICâˆ—. For smaller parameter values, smaller sample sizes, and more censoring, the selection probability of the true model was larger for BICâˆ—
than for BICF. The selection probability of the full model for BICF showed the smallest value. Although a BIC-type criterion was designed to identify the true model as n â†’ âˆž, the selection probability of the true model of BICâˆ— was smaller than that of BICF for a large number of samples. For instance, in the case with c = 0%, ðœƒ = 16, and n = 1000, the selection probability of the true model for BICF and BICâˆ— were 0.991 and 0.668, while the selection probability of the full model for BICF and BICâˆ— were 0.001 and 0.151. This is because of the properties of BICâˆ— discussed in Section 3.3.
The results of the other models and conditions are presented in Data S2 (Tables S1â€“S8 for bias, Table
S9 for prediction performance, and Tables S10â€“S17 for selection probability); these results reveal the
same tendencies as discussed previously. In summary, AICF can estimate the risk function and shows better prediction performance than AICâˆ—.
By contrast, because AICâˆ— selects models that have many parameters and ignores the adequacy of the

3431

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO
model as the number of events increase, it is not as efficient and not recommended for model selection. BICF can select the true model as n â†’ âˆž. In contrast, because the selection probability of the true model for BICâˆ— was smaller than that for BICF for a large number of samples, this method is not as efficient in selecting the true model.
5. Application of the prospective observational study data
Next, we apply the proposed method to the study introduced in Section 2. We select a model based on AICF as in that section, with the result shown in Table VI. As AICâˆ— tends to select models that have many parameters (Table II), the model that includes ntumor (number of tumors), ptumor (primary tumor category), and neuro (neurological symptoms) was selected by AICF as the best. The best model under AICF does not include unnecessary covariates such as age and status whose hazard ratios were almost equal to one (Table II).
The estimated hazard ratios for the best model are shown in Table VII. The best model under AICF included ntumor (1 vs. 2â€“4: HR = 0.71, p-value = 0.08; 5â€“10 vs. 2â€“4: HR = 1.57, p-value = 0.04), ptumor (breast vs. lung: HR = 0.94, p-value = 0.82; gastrointestinal vs. lung: HR = 1.60, p-value = 0.21; kidney vs. lung: HR = 0.12, p-value = 0.02; others vs. lung: HR = 0.87, p-value = 0.79), and neuro (HR = 1.53, p-value = 0.04). The selected covariates under AICF are better than age (Table III; HR = 1.00, p-value = 0.98) and status (Table III; HR = 1.03, p-value = 0.85). Therefore, the best model under AICF seems to be plausible and may be more appropriate than the best model under AICâˆ—. Additionally, the best model under AICF is clinically interpretable because the selected variables are prognostic factors for brain metastases [20â€“22].
6. Discussion and conclusion
One solution to the monotone likelihood problem, which is an important issue in Cox regression models, is Firthâ€™s penalized partial likelihood approach. However, the model selection criteria for this approach are yet to be studied, and heuristic criteria, AICâˆ— and BICâˆ—, are used in the SAS PHREG procedure. Therefore,

Table VI. The top five models based on AICF for the study data.

Model

AICF

ntumor

ptumor

neuro 1753.84

ntumor

neuro 1754.72

sex

ntumor

ptumor

neuro 1754.90

ntumor diameter

ptumor

neuro 1755.83

ntumor

ptumor status neuro 1755.83

Note: ntumor, number of tumors; diameter, maximum diameter of largest tumor; ptumor, primary tumor category; status, extracerebral disease status; neuro, neurological symptoms; AICF, AIC for Firthâ€™s penalized partial likelihood approach.

Table VII. Parameter estimates of the best model based on AICF for the study data.

Covariate

HR SE 95% CI p (LR)

ntumor

1 vs. 2â€“4

0.71 0.19 0.49 1.05 0.08

5â€“10 vs. 2â€“4

1.57 0.21 1.03 2.38 0.04

ptumor

Breast vs. lung

0.94 0.26 0.57 1.57 0.82

GI vs. lung

1.60 0.36 0.79 3.26 0.21

Renal cell vs. lung 0.12 1.43 0.01 1.99 0.02

Others vs. lung

0.87 0.55 0.30 2.56 0.79

neuro (yes vs. no) 1.53 0.20 1.04 2.24 0.04

Note: HR, hazard ratio; ntumor, number of tumors; ptumor, primary tumor category; neuro, neurological symptoms; GI, gastrointestinal; LR, likelihood ratio; SE, standard error.

3432

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

in this study, we proposed alternative criteria, AICF and BICF, which work for Firthâ€™s penalized partial likelihood approach. Moreover, we discussed the justification for adopting Firthâ€™s bias correction method in Cox regression models.
We showed that AICF, an estimator of the risk function based on KL information, does not include the penalty term of AICâˆ—, 0.5 log |ðˆ(ðœ·Ì‚ )|. Even in the penalized partial likelihood setting, non-penalized likelihood should be used for risk estimation. In addition, AICF is more efficient than AICâˆ— in simulations and works well when addressing monotone likelihood. The simulation results revealed systematic bias in AICâˆ—, and the model selection based on AICF showed superior predictive performance. In any case, AICâˆ— is not recommended for model selection. An application using real data concluded that AICF has better properties than AICâˆ— and that the latter leads to incorrect results. Moreover, we showed that BICâˆ— has a negative penalty term in proportion to the number of regression parameters. The selection probability of the true model for BICâˆ— was smaller than that of BICF for a large number of samples, indicating that it is not as efficient for selecting the true model. In summary, we showed that AICF or BICF is appropriate for model selection in monotone likelihood cases. AICF would be used for prediction, while BICF can be used for selecting the true model.
Because we obtained impressive results with alternative criteria, future studies should aim to examine other model evaluation criteria such as the C-index [23, 24]. Moreover, a similar problem occurs if one uses AIC and BIC based on the penalized log-likelihood under separation in logistic regression models.

Appendix A. Justification for using Firthâ€™s bias correction method in Cox regression models
Firthâ€™s bias correction method is based on the relationships ðœ…j,k +ðœ…jk = 0, ðœ…j,k,l +ðœ…j,kl +ðœ…k,jl +ðœ…l,jk +ðœ…j,k,l = 0, and ðœ…j,kl = 0, as discussed in Section 3.2. However, the relationships ðœ…j,k,l + ðœ…j,kl + ðœ…k,jl + ðœ…l,jk + ðœ…j,k,l = 0 and ðœ…j,kl = 0 have not yet been evaluated in Cox regression models. Therefore, we only prove that ðœ…j,kl = 0; it is well known that ðœ…j,k + ðœ…jk = 0, and we can easily show that ðœ…j,k,l + ðœ…jkl = 0. Lemma 1 (ðœ…j,kl = 0.)

Proof If we insert ðœ·0 in the functions Uj(ðœ·) and Ukl(ðœ·),

âˆ‘n 1 Uj(ðœ·0) = i=1 âˆ«0 Hij(x) dMi(x),

Hij(t)

=

Zij(t)

âˆ’

Sj(1) (ðœ· 0 , S(0) (ðœ· 0 ,

t) ,
t)

and

âˆ‘n 1 Ukl(ðœ·0) = âŸ¨Ukl(ðœ·0)âŸ©(1) + i=1 âˆ«0 Gkl(x) dMi(x),

Gkl(t)

=

Sk(2l )(ðœ·0, t) S(0)(ðœ·0, t)

âˆ’

Sk(1)(ðœ·0, t)Sl(1)(ðœ·0, t) , {S(0)(ðœ·0, t)}2

where

Sj(1)(ðœ·, t)

=

nâˆ’1

âˆ‘n
i=1

Yi(t)Zij(t)

exp{ðœ·

Tð™i(t)},

Sk(2l)(ðœ·, t)

=

nâˆ’1

âˆ‘n
i=1

Yi(t)Zik

(t)Zil(t)

exp{ðœ· T ð™i (t)},

and âŸ¨Ukl(ðœ·0)âŸ©(t) = n âˆ«0t Gkl(x)S(0)(ðœ·0, x)h0(x) dx.

We note that Hij and Gkl are predictable processes according to the assumption made in Section 3.1.

Here,

âˆ‘n 1

Uj(ðœ·0)Ukl(ðœ·0) = âŸ¨Ukl(ðœ·0)âŸ©(1) i=1 âˆ«{0 Hij(x) dMi(x)+

}{

}

âˆ‘n 1

âˆ‘n 1

i=1 âˆ«0 Hij(x) dMi(x)

i=1 âˆ«0 Gkl(x) dMi(x) .

3433

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

From theorem 2.4.4 of [25], we have

[

âˆ‘n 1

ðœ…j,kl = nâˆ’1E âŸ¨Ukl(ðœ·0)âŸ©(1) i=1 âˆ«0 Hij(x) dMi(x)+ âˆ‘n âˆ‘n 1

]

h=1 i=1 âˆ«0 Hhj(x)Gkl(x) dâŸ¨Mh, MiâŸ©(x) .

Because Mi(t) is the counting process martingale,

[

]

âˆ‘n 1

E i=1 âˆ«0 Hij(x) dMi(x) = 0,

and from the orthogonality of martingales

âŸ¨Mh,

MiâŸ©(t)

=

{

âˆ«0tYh(x)

exp{ðœ·T0 ð™h(x)}h0(x)

dx, 0,

h=i hâ‰ i

It follows that

ðœ…j,kl

=

0

+

[ nâˆ’1E âˆ«0

1[

âˆ‘n
i=1

{ Zij(x)

âˆ’

Sj(1) (ðœ· 0 , S(0) (ðœ· 0 ,

x) x)

} Yi(x)

] exp{ðœ·T0 ð™i(x)} Gkl(x)h0(x)

] dx

= 0.

Therefore, the relationships ðœ…j,k + ðœ…jk = 0, ðœ…j,k,l + ðœ…j,kl + ðœ…k,jl + ðœ…l,jk + ðœ…jkl = 0, and ðœ…j,kl = 0 are also true in Cox regression models.

Appendix B. Consistency of ðœ·Ì‚
In this section, we discuss the consistency of ðœ·Ì‚ . The following list of conditions will be assumed: (A) âˆ«01 h0(x) dx < âˆž. (B) There exists a neighborhood B of ðœ·0 and a scalar function, s(0), a vector function, ð¬(1), and a matrix function, ð¬(2), defined on B Ã— [0, 1] such that for k = 0, 1, 2,

sup

||ð’(k) (ðœ· ,

t)

âˆ’

ð¬(k) (ðœ· ,

t)||

P
âˆ’â†’

0.

tâˆˆ[0,1],ðœ·âˆˆB

(C) There exists ð›¿ > 0 such that

nâˆ’1âˆ•2

sup
tâˆˆ[0,1],1â‰¤iâ‰¤n

|ð™i

(t)|Yi

(t)1{ðœ·

T 0

ð™i

(t)>âˆ’ð›¿|ð™i

(t)|}

P
âˆ’â†’

0,

where 1{} is an indicator function. (D) For all ðœ· âˆˆ B, t âˆˆ [0, 1]: s(0)(ðœ·, t), ð¬(1)(ðœ·, t) = ðœ•s(0)(ðœ·, t)âˆ•ðœ•ðœ·, and ð¬(2)(ðœ·, t) = ðœ•ð¬(1)(ðœ·, t)âˆ•ðœ•ðœ·T are continuous functions of ðœ· âˆˆ B, uniformly in t âˆˆ [0, 1], s(0), ð¬(1), and ð¬(2) are bounded on B Ã— [0, 1]; s(0) is bounded away from zero on B Ã— [0, 1], and the matrix ðšº(ðœ·0) is positive definite.
These conditions are identical to those given by Andersen and Gill [12].
Lemma 2 (ðœ·Ì‚ â†’ ðœ·0.)

Proof Consider the process

Xnâˆ—(ðœ·, 1) = nâˆ’1{lâˆ—(ð, ð˜, ð™; ðœ·) âˆ’ lâˆ—(ð, ð˜, ð™; ðœ·0)} = Xn(ðœ·, 1) + 0.5nâˆ’1{log |ðˆ(ðœ·)| âˆ’ log |ðˆ(ðœ·0)|},

3434

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO

ewshtiemreatXonr(ðœ·ðœ·Ì‚ C, o1x),

= nâˆ’1{l(ð, ð˜, Andersen and

ð™; ðœ·)âˆ’l(ð, ð˜, ð™; ðœ·0)}. To prove Gill [12] showed that Xn(ðœ·, 1) is

the consistency of the usual Cox regression a concave function and proved that Xn(ðœ·, 1)

converges in probability to

A(ðœ·,

1)

=

âˆ«0

1

[ (ðœ·

âˆ’

ðœ· 0 )T ð¬(1) (ðœ· 0 ,

x)

âˆ’

log

{ s(0)(ðœ·, x) s(0)(ðœ·0, x)

}

s(0) (ðœ· 0 ,

] x)

h0(t)

dx,

for each ðœ· âˆˆ B. The first derivative of A(ðœ·, 1) is zero at ðœ· = ðœ·0, and the second derivative is minus a positive definite matrix. In other words, A(ðœ·, 1) is a concave function of ðœ· with a unique maximum at

ðœ·

=

ðœ·0.

If

Xn (ðœ· ,

1)

is

a

concave

function,

then

ðœ·Ì‚ Cox

P
âˆ’â†’

ðœ·0

by

applying

theorem

II.1

of

[12].

In the same manner, if unique maximum at ðœ· =

ðœ·X0nâˆ—,(tðœ·h,e1c)oinsscisotnecnacvyeoafnðœ·Ì‚d

Xnâˆ—(ðœ·, 1) converges to a concave function can be shown by applying theorem II.1 of

of ðœ· [12].

with

a

In monotone likelihood settings, the partial log-likelihood function converges to a finite value. Fixing

ð›½1, ð›½2, â€¦ , ð›½jâˆ’1, ð›½j+1, â€¦ , ð›½p to be ð›½Ì‚1, ð›½Ì‚2, â€¦ , ð›½Ì‚jâˆ’1, ð›½Ì‚j+1, â€¦ , ð›½Ì‚p, for the parameter ð›½j, a real number c, and a

constant d,

âˆƒc, âˆ€ð›½j â‰¥ c, l(ð, ð˜, ð™; ð›½Ì‚1, ð›½Ì‚2, â€¦ , ð›½Ì‚jâˆ’1, ð›½j, ð›½Ì‚j+1, â€¦ , ð›½Ì‚p) = d, or
âˆƒc, âˆ€ð›½j â‰¤ c, l(ð, ð˜, ð™; ð›½Ì‚1, ð›½Ì‚2, â€¦ , ð›½Ì‚jâˆ’1, ð›½j, ð›½Ì‚j+1, â€¦ , ð›½Ì‚p) = d,

in monotone likelihood settings. Therefore, Xn(ðœ·, 1) is a concave function. Note that l(ð, ð˜, ð™; ðœ·0) and log |ðˆ(ðœ·0)| are obviously finite constants. Thus, it is sufficient to show that log |ðˆ(ðœ·)| is a concave function. Now, ðˆ(ðœ·) is a positive semidefinite matrix (see also Prentice [26]) because l(ð, ð˜, ð™; ðœ·) is a concave

function. Generally, the function log |ð‚|, where |ð‚| is the determinant of a positive semidefinite matrix

ð‚,Wiseconnecxatvseh[o2w7]t.hTaht eXrenâˆ—f(oðœ·r,e1, )Xcnâˆ—o(ðœ·nv, 1er)giessa

sum of concave functions. in probability to A(ðœ·, 1). According

to

the

aforementioned

result, Xn(ðœ·, 1) converges in probability to A(ðœ·, 1). Conditions (B) and (D) imply that, for each ðœ· âˆˆ B,

nâˆ’1 ðˆ(ðœ· )

P
âˆ’â†’

ðšº(ðœ·).

Thus,

log |ðˆ(ðœ·)| âˆ’ log |ðˆ(ðœ·0)| = log |n â‹… nâˆ’1ðˆ(ðœ·)| âˆ’ log |n â‹… nâˆ’1ðˆ(ðœ·0)| = log |nâˆ’1ðˆ(ðœ·)| âˆ’ log |nâˆ’1ðˆ(ðœ·0)| = log{nâˆ’p|ðˆ(ðœ·)|} âˆ’ log{nâˆ’p|ðˆ(ðœ·0)|}

converges in probability to some finite quantity. Therefore,

0.5nâˆ’1

{ log

|ðˆ(ðœ· )|

âˆ’

log

} |ðˆ(ðœ· 0 )|

P
âˆ’â†’

0,

and Xnâˆ—(ðœ·, 1) converges in probability to A(ðœ·, 1), which is a concave function of ðœ· with a unique maximum

at ðœ· = ðœ·0.

These

facts

establish

that

ðœ·Ì‚

P
âˆ’â†’

ðœ·0

as

n

â†’

âˆž.

Moreover,

from

this

consistency,

we

can

apply

theorem

3.2

of

[12];

therefore,

nâˆ’1ðˆ(ðœ·Ì‚ )

P
âˆ’â†’

Î£(ðœ· 0 )

in

monotone likelihood settings.

Acknowledgements
The authors would like to thank the associate editor and two reviewers for very insightful and constructive comments that substantially improved the article. The authors would like to thank Professor Masaaki Yamamoto of Katsuta Hospital Mito Gamma House and Dr. Toru Serizawa of Tsukiji Neurological Clinic for providing the dataset of the JLGK0901 study. This work was supported by the Japan Society for the Promotion of Science KAKENHI grant numbers 26870099 and 16K16014 and the MHLW-funded Core Clinical Research Centers.

References
1. Cox DR. Regression models and life tables (with discussion). Journal of the Royal Statistical Society, Series B 1972; 34(2):187â€“220.
2. Bryson MC, Johnson ME. The incidence of monotone likelihood in the Cox model. Technometrics 1981; 23(4):381â€“383.

3435

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

K. NAGASHIMA AND Y. SATO
3. Heinze G, Schemper M. A solution to the problem of monotone likelihood in Cox regression. Biometrics 2001; 57(1): 114â€“119.
4. Firth D. Bias reduction of maximum likelihood estimates. Biometrika 1993; 80(1):27â€“38. 5. Heinze G. The application of Firthâ€™s procedure to Cox and logistic regression, Technical Report 10/1999, update in January
2001, Section of Clinical Biometrics, Department of Medical Computer Sciences University of Vienna, 2001. 6. Heinze G. A comparative investigation of methods for logistic regression with separated or nearly separated data. Statistics
in Medicine 2006; 25(24):4216â€“4226. 7. Heinze G, Schemper M. A solution to the problem of separation in logistic regression. Statistics in Medicine 2002;
21(16):2409â€“2419. 8. Akaike H. Information theory and an extension of the maximum likelihood principle. In In Second International Symposium
on Information Theory, Petrov BN, Csaki F (eds). Akademiai Kiado: Budapest, 1973; 267â€“281. 9. Schwarz G. Estimating the dimension of a model. The Annals of Statistics 1978; 6(2):461â€“464. 10. Yamamoto M, Serizawa T, Shuto T, Akabane A, Higuchi Y, Kawagishi J, Yamanaka K, Sato Y, Jokura H, Yomo S, Nagano
O, Kenai H, Moriki A, Suzuki S, Kida Y, Iwai Y, Hayashi M, Onishi H, Gondo M, Sato M, Akimitsu T, Kubo K, Kikuchi Y, Shibasaki T, Goto T, Takanashi M, Mori Y, Takakura K, Saeki N, Kunieda E, Aoyama H, Momoshima S, Tsuchiya K. Stereotactic radiosurgery for patients with multiple brain metastases (JLGK0901): a multi-institutional prospective observational study. The Lancet Oncology 2014; 15(4):387â€“395. 11. Kalbfleisch JD, Prentice RL. The Statistical Analysis of Failure Time Data 2nd ed. John Wiley & Sons: New Jersey, 2002. 12. Andersen PK, Gill RD. Coxâ€™s regression model for counting processes: a large sample study. The Annals of Statistics 1982; 10(4):1100â€“1120. 13. Cox DR, Snell EJ. A general definition of residuals. Journal of the Royal Statistical Society, Series B 1968; 30(2):248â€“275. 14. Volinsky CT, Raftery AE. Bayesian information criterion for censored survival models. Biometrics 2000; 56(1):256â€“262. 15. Xu R, Vaida F, Harrington DP. Using profile likelihood for semiparametric model selection with application to proportional hazards mixed models. Statistica Sinica 2009; 19(2):819â€“842. 16. Claeskens G, Carroll RJ. An asymptotic theory for model selection inference in general semiparametric problems. Biometrika 2007; 94(2):249â€“265. 17. Bailey KR. The asymptotic joint distribution of regression and survival parameter estimates in the Cox regression model. The Annals of Statistics 1983; 11(1):39â€“48. 18. Johansen S. An extension of Coxâ€™s regression model. International Statistical Review 1983; 51(2):165â€“174. 19. Murphy SA, van der Vaart AW. On profile likelihood. Journal of the American Statistical Association 2000; 95(450): 449â€“465. 20. Joseph J, Adler J R, Cox R S, Hancock S L. Linear accelerator-based stereotaxic radiosurgery for brain metastases: the influence of number of lesions on survival. Journal of Clinical Oncology 1996; 14(4):1085â€“1092. 21. Balm M, Hammack J. Leptomeningeal carcinomatosis. Presenting features and prognostic factors. Archives of Neurology 1996; 53(7):626â€“632. 22. Sperduto PW, Kased N, Roberge D, Xu Z, Shanley R, Luo X, Sneed PK, Chao ST, Weil RJ, Suh J, Bhatt A, Jensen AW, Brown PD, Shih HA, Kirkpatrick J, Gaspar LE, Fiveash JB, Chiang V, Knisely JP, Sperduto CM, Lin N, Mehta M. Summary report on the graded prognostic assessment: an accurate and facile diagnosis-specific tool to estimate survival for patients with brain metastases. Journal of Clinical Oncology 2012; 30(4):419â€“425. 23. Harrell FE, Lee KL, Mark DB. Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors. Statistics in Medicine 1996; 15(4):361â€“387. 24. Uno H, Cai T, Pencina MJ, Dâ€™Agostino RB, Wei LJ. On the C-statistics for evaluating overall adequacy of risk prediction procedures with censored survival data. Statistics in Medicine 2011; 30(10):1105â€“1117. 25. Fleming T R, Harrington D P. Counting Processes and Survival Analysis. John Wiley & Sons: New York, 1991. 26. Prentice RL, Self SG. Asymptotic distribution theory for Cox-type regression models with general relative risk form. The Annals of Statistics 1983; 11(3):804â€“813. 27. Cover TM, Thomas JA. Determinant inequalities via information theory. SIAM Journal on Matrix Analysis and Applications 1988; 9(3):384â€“392.
Supporting information
Additional supporting information may be found in the online version of this article at the publisherâ€™s web-site.

3436

Â© 2017 The Authors. Statistics in Medicine Published by John Wiley & Sons Ltd

Statist. Med. 2017, 36 3422â€“3436

