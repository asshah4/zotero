A PRIMER ON REGRESSION SPLINES
JEFFREY S. RACINE
1. Overview
B-splines constitute an appealing method for the nonparametric estimation of a range of statistical objects of interest. In this primer we focus our attention on the estimation of a conditional mean, i.e. the ‘regression function’.
A ‘spline’ is a function that is constructed piece-wise from polynomial functions. The term comes from the tool used by shipbuilders and drafters to construct smooth shapes having desired properties. Drafters have long made use of a bendable strip ﬁxed in position at a number of points that relaxes to form a smooth curve passing through those points. The malleability of the spline material combined with the constraint of the control points would cause the strip to take the shape that minimized the energy required for bending it between the ﬁxed points, this being the smoothest possible shape. We shall rely on a class of splines called ‘B-splines’ (‘basis-splines’). A B-spline function is the maximally diﬀerentiable interpolative basis function. The B-spline is a generalization of the B´ezier curve (a B-spline with no ‘interior knots’ is a B´ezier curve). B-splines are deﬁned by their ‘order’ m and number of interior ‘knots’ N (there are two ‘endpoints’ which are themselves knots so the total number of knots will be N +2). The degree of the B-spline polynomial will be the spline order m minus one (degree = m − 1).
To best appreciate the nature of B-splines, we shall ﬁrst consider a simple type of spline, the B´ezier function, and then move on to the more ﬂexible and powerful generalization, the B-spline itself. We begin with the univariate case in Section 2 where we consider the univariate B´ezier function. In Section 3 we turn to the univariate B-spline function, and then in Section 4 we turn to the multivariate case where we also brieﬂy mention how one could handle the presence of categorical predictors.
We presume that interest lies in ‘regression spline’ methodology which diﬀers in a number of ways from ‘smoothing splines’, both of which are popular in applied settings. The fundamental diﬀerence between the two approaches is that smoothing splines explicitly penalize roughness and use the data points themselves as potential knots whereas regression splines place knots at equidistant/equiquantile points. We direct the interested reader to Wahba (1990) for a treatment of smoothing splines.
Date: May 1, 2018. These notes are culled from a variety of sources. I am solely responsible for all errors. Suggestions are welcomed (racinej@mcmaster.ca).
1

2

JEFFREY S. RACINE

2. Be´zier curves

We present an overview of B´ezier curves which form the basis for the B-splines that follow. We begin with a simple illustration, that of a quadratic B´ezier curve.

Example 2.1. A quadratic B´ezier curve. A quadratic B´ezier curve is the path traced by the function B(x), given points β0,
β1, and β2, where
B(x) = β0(1 − x)2 + 2β1(1 − x)x + β2x2
2
= βiBi(x), x ∈ [0, 1].
i=0
The terms B0(x) = (1 − x)2, B1(x) = 2(1 − x)x, and B2(x) = x2 are the ‘bases’ which is this case turn out to be ‘Bernstein polynomials’ (Bernstein (1912)). For our purposes the ‘control points’ βi, i = 0, 1, 2, will be parameters that could be selected by least squares ﬁtting in a regression setting, but more on that later. Consider the following simple example where we plot a quadratic B´ezier curve with arbitrary control points:

2.0

1.5

B(x)

1.0

0.5

0.0

0.2

0.4

0.6

0.8

1.0

x

For this simple illustration we set β0 = 1, β1 = −1, β2 = 2. Note that the derivative of this curve is
B′(x) = 2(1 − x)(β1 − β0) + 2x(β2 − β1),
which is a polynomial of degree one. This example of a B´ezier curve will also be seen to be a ‘second-degree B-spline with
no interior knots’ or, equivalently, ‘a third-order B-spline with no interior knots’. Using the terminology of B-splines, in this example we have a third-order B-spline (m = 3) which is of polynomial degree two (m − 1 = 2) having highest derivative of polynomial degree one (m − 2 = 1).

A PRIMER ON REGRESSION SPLINES

3

2.1. The B´ezier curve deﬁned. More generally, a B´ezier curve of degree n (order m) is composed

of m = n + 1 terms and is given by

B(x) =

n

βi

n i

(1 − x)n−ixi

i=0

n

(1)

= βiBi,n(x),

i=0

where

n i

=

n! (n−i)!i!

,

which

can

be

expressed

recursively

as

n−1

n

B(x) = (1 − x)

βiBi,n−1(x) + x

βiBi−1,n−1(x) ,

i=0

i=1

so a degree n B´ezier curve is a linear interpolation between two degree n − 1 B´ezier curves.

Example 2.2. A quadratic B´ezier curve as a linear interpolation between two linear B´ezier curves.
The linear B´ezier curve is given by β0(1 − x) + β1x, and above we showed that the quadratic B´ezier curve is given by β0(1 − x)2 + 2β1(1 − x)x + β2x2. So, when n = 2 (quadratic), we have
B(x) = (1 − x)(β0(1 − x) + β1x) + x(β1(1 − x) + β2x) = β0(1 − x)2 + 2β1(1 − x)x + β2x2.

This is essentially a modiﬁed version of the idea of taking linear interpolations of linear interpo-

lations of linear interpolations and so on. Note that the polynomials

Bi,n(x) =

n i

(1 − x)n−ixi

are called ‘Bernstein basis polynomials of degree n’ and are such that

n i=0

Bi,n(x)

=

1,

unlike

raw

polynomials.1

The m = n + 1 control points βi, i = 0, . . . , n, are somewhat ancillary to the discussion here,

but will ﬁgure prominently when we turn to regression as in a regression setting they will be the

coeﬃcients of the regression model.

1Naturally we deﬁne x0 = (1 − x)0 = 1, and by ‘raw’ polynomials we simply mean xj, j = 0, . . . , n.

4

JEFFREY S. RACINE

Example 2.3. The quadratic B´ezier curve basis functions.
The ﬁgure below presents the bases Bi,n(x) underlying a B´ezier curve for i = 0, . . . , 2 and n = 2.

1.0

0.8

0.6

B(x)

0.4

0.2

0.0

0.0

0.2

0.4

0.6

0.8

1.0

x

These bases are B0,2(x) = (1 − x)2, B1,2(x) = 2(1 − x)x, and B2,2(x) = x2 and illustrate the foundation upon which the B´ezier curves are built.

2.2. Derivatives of spline functions. From de Boor (2001) we know that the derivatives of

spline functions can be simply expressed in terms of lower order spline functions. In particular, for

the B´ezier curve we have where βi(0) = βi, 0 ≤ i ≤ n, and

n−l

B(l)(x) =

βi(l)Bi,n−l(x),

i=0

βi(l) = (n − l) βi(+l−11) − βi(l−1) /(ti − ti−n+l), 0 ≤ i ≤ n − l.

See Zhou & Wolfe (2000) for details. We now turn our attention to the B-spline function. This can be thought of as a generalization of
the B´ezier curve where we now allow for there to be additional breakpoints called ‘interior knots’.

3. B-splines
3.1. B-spline knots. B-spline curves are composed from many polynomial pieces and are therefore more versatile than B´ezier curves. Consider N + 2 real values ti, called ‘knots’ (N ≥ 0 are called ‘interior knots’ and there are always two endpoints, t0 and tN+1), with
t0 ≤ t1 ≤ · · · ≤ tN+1.
When the knots are equidistant they are said to be ‘uniform’, otherwise they are said to be ‘nonuniform’. One popular type of knot is the ‘quantile’ knot sequence where the interior knots are the quantiles from the empirical distribution of the underlying variable. Quantile knots guarantee that

A PRIMER ON REGRESSION SPLINES

5

an equal number of sample observations lie in each interval while the intervals will have diﬀerent lengths (as opposed to diﬀerent numbers of points lying in equal length intervals).
B´ezier curves possess two endpoint knots, t0 and t1, and no interior knots hence are a limiting case, i.e. a B-spline for which N = 0.

3.2. The B-spline basis function. Let t = {ti | i ∈ Z} be a sequence of non-decreasing real numbers (ti ≤ ti+1) such that2
t0 ≤ t1 ≤ · · · ≤ tN+1.
Deﬁne the augmented the knot set

t−(m−1) = · · · = t0 ≤ t1 ≤ · · · ≤ tN ≤ tN+1 = · · · = tN+m,

where we have appended the lower and upper boundary knots t0 and t1 n = m − 1 times (this is needed due to the recursive nature of the B-spline). If we wanted we could then reset the index for the ﬁrst element of the augmented knot set (i.e. t−(m−1)) so that the N + 2m augmented knots ti are now indexed by i = 0, . . . , N + 2m − 1 (see the example below for an illustration).
For each of the augmented knots ti, i = 0, . . . , N +2m−1, we recursively deﬁne a set of real-valued functions Bi,j (for j = 0, 1, . . . , n, n being the degree of the B-spline basis) as follows:

Bi,0(x) =

1 if ti ≤ x < ti+1 0 otherwise.

Bi,j+1(x) = αi,j+1(x)Bi,j (x) + [1 − αi+1,j+1(x)]Bi+1,j (x),

where

 

x − ti

αi,j(x) = 

ti+j 0

− ti

if ti+j = ti otherwise.

For the above computation we deﬁne 0/0 as 0. Deﬁnitions. Using the notation above:
(1) the sequence t is known as a knot sequence, and the individual term in the sequence is a knot.
(2) the functions Bi,j are called the i-th B-spline basis functions of order j, and the recurrence relation is called the de Boor recurrence relation, after its discoverer Carl de Boor (de Boor (2001)).
(3) given any non-negative integer j, the vector space Vj(t) over R, generated by the set of all B-spline basis functions of order j is called the B-spline of order j. In other words, the B-spline Vj(t) = span{Bi,j(x) | i = 0, 1, . . .} over R.
(4) Any element of Vj(t) is a B-spline function of order j.

2This description is based upon the discussion found at http://planetmath.org/encyclopedia/BSpline.html.

6

JEFFREY S. RACINE

The ﬁrst term B0,n is often referred to as the ‘intercept’. In typical spline implementations

the option intercept=FALSE denotes dropping this term while intercept=TRUE denotes keeping

it (recall that

n i=0

Bi,n(x)

=

1

which

can

lead

to

perfect

multicollinearity

in

a

regression

setting;

also see Zhou & Wolfe (2000) who instead apply shrinkage methods).

Example 3.4. A fourth-order B-spline basis function with three interior knots and its ﬁrst derivative function.
Suppose there are N = 3 interior knots given by (0.25, 0.5, 0.75), the boundary knots are (0, 1), and the degree of the spline is n = 3 hence the order is m = 4. The set of all knot points needed to construct the B-spline is
(0, 0, 0, 0, 0.25, 0.5, 0.75, 1, 1, 1, 1)
and the number of basis functions is K = N + m = 7. The seven cubic spline basis functions will be denoted B0,3, . . . , B6,3.
The ﬁgure below presents this example of a third degree B-spline with three interior knots along with its ﬁrst derivative (the spline derivatives would be required in order to compute derivatives from the spline regression model).

1.0

10

0.8

5

0.6

0

B.deriv

B

0.4

−5

0.2

−10

0.0

0.0

0.2

0.4

0.6

0.8

1.0

x

0.0

0.2

0.4

0.6

0.8

1.0

x

To summarize, in this illustration we have an order m = 4 (degree = 3) B-spline (left) with 4 sub-intervals (segments) using uniform knots (N = 3 interior knots, 5 knots in total (2 endpoint knots)) and its 1st-order derivative (right). The dimension of B(x) is K = N + m = 7.

See the appendix for R code (R Development Core Team (2011)) that implements the B-spline basis function.

3.3. The B-spline function. A B-spline of degree n (of spline order m = n + 1) is a parametric curve composed of a linear combination of basis B-splines Bi,n(x) of degree n given by

N +n

(2)

B(x) = βiBi,n(x), x ∈ [t0, tN+1].

i=0

A PRIMER ON REGRESSION SPLINES

7

The βi are called ‘control points’ or ‘de Boor points’. For an order m B-spline having N interior knots there are K = N + m = N + n + 1 control points (one when j = 0).
The B-spline order m must be at least 2 (hence at least linear, i.e. degree n is at least 1) and the number of interior knots must be non-negative (N ≥ 0).
See the appendix for R code (R Development Core Team (2011)) that implements the B-spline function.

4. Multivariate B-spline regression
The functional form of parametric regression models must naturally be speciﬁed by the user. Typically practitioners rely on raw polynomials and also often choose the form of the regression function (i.e. the order of the polynomial for each predictor) in an ad-hoc manner. However, raw polynomials are not suﬃciently ﬂexible for our purposes, particularly because they possess no interior knots which is where B-splines derive their unique properties. Furthermore, in a regression setting we typically encounter multiple predictors which can be continuous or categorical in nature, and traditional splines are for continuous predictors. Below we brieﬂy describe a multivariate kernel weighted tensor product B-spline regression method (kernel weighting is used to handle the presence of the categorical predictors). This method is implemented in the R package ‘crs’ (Racine & Nie (2011)).
4.1. Multivariate knots, intervals, and spline bases. In general we will have q predictors, X = (X1, . . . , Xq)T . We assume that each Xl, 1 ≤ l ≤ q, is distributed on a compact interval [al, bl], and without loss of generality, we take all intervals [al, bl] = [0, 1]. Let Gl = G(lml−2) be the space of polynomial splines of order ml. We note that Gl consists of functions ̟ satisfying (i) ̟ is a polynomial of degree ml − 1 on each of the sub-intervals Ijl,l, jl = 0, . . . , Nl; (ii) for ml ≥ 2, ̟ is ml − 2 times continuously diﬀerentiable on [0, 1].
Pre-select an integer Nl = Nn,l. Divide [al, bl] = [0, 1] into (Nl + 1) sub-intervals Ijl,l = [tjl,l, tjl+1,l), jl = 0, . . . , Nl − 1, INl,l = [tNl,l, 1], where {tjl,l}Njl=l 1 is a sequence of equally-spaced points, called interior knots, given as
t−(ml−1),l = · · · = t0,l = 0 < t1,l < · · · < tNl,l < 1 = tNl+1,l = · · · = tNl+ml,l,
in which tjl,l = jlhl, jl = 0, 1 . . . , Nl + 1, hl = 1/ (Nl + 1) is the distance between neighboring knots. Let Kl = Kn,l = Nl + ml, where Nl is the number of interior knots and ml is the spline order,
and let Bl (xl) = {Bjl,l (xl) : 1 − ml ≤ jl ≤ Nl}T be a basis system of the space Gl.

8

JEFFREY S. RACINE

We deﬁne the space of tensor-product polynomial splines by G = ⊗ql=1Gl. It is clear that G is a

linear space of dimension Kn =

q l=1

Kl

.

Then3

B (x) =

Bj1,...,jq (x)

N1,...,Nq j1 =1−m1 ,...,jq =1−mq

= B1 (x1) ⊗ · · · ⊗ Bq (xq)
Kn×1

is a basis system of the space G, where x = (xl)ql=1. Let B =

{B (X1) , . . . , B (Xn)}T

.
n×Kn

4.2. Spline regression. In what follows we presume that the reader is interested in the unknown conditional mean in the following location-scale model,

(3)

Y = g (X, Z) + σ (X, Z) ε,

where g(·) is an unknown function, X = (X1, . . . , Xq)T is a q-dimensional vector of continuous

predictors, and Z = (Z1, . . . , Zr)T is an r-dimensional vector of categorical predictors. Letting

z = (zs)rs=1, we assume that zs takes cs diﬀerent values in Ds ≡ {0, 1, . . . , cs − 1}, s = 1, . . . , r, and

let cs be a ﬁnite positive constant. Let

Yi, XTi , ZTi

n i=1

be

an

i.i.d

copy

of

Y, XT, ZT . Assume for

1 ≤ l ≤ q, each Xl is distributed on a compact interval [al, bl], and without loss of generality, we

take all intervals [al, bl] = [0, 1].

In order to handle the presence of categorical predictors, we deﬁne

l (Zs, zs, λs) =

1,when Zs = zs , λs, otherwise.

r

r

(4)

L (Z, z, λ) = l (Zs, zs, λs) = λ1s(Zs=zs),

s=1

s=1

where l(·) is a variant of Aitchison & Aitken’s (1976) univariate categorical kernel function, L(·) is a product categorical kernel function, and λ = (λ1, λ2, . . . , λr)T is the vector of bandwidths for each of the categorical predictors. See Ma, Racine & Yang (under revision) and Ma & Racine (2013) for further details.
We estimate β (z) by minimizing the following weighted least squares criterion,

β (z) = arg min

n

Yi − B (Xi)T β

2
L (Zi, z, λ) .

β∈RKn i=1

Let Lz = diag {L (Z1, z, λ) , . . . , L (Zn, z, λ)} be a diagonal matrix with L (Zi, z, λ), 1 ≤ i ≤ n as the diagonal entries. Then β (z) can be written as

(5)

β (z) = n−1BTLzB −1 n−1BTLzY ,

3The notation here may throw oﬀ those used to sums of the form

n i=1

,

n

>

0

(i.e.

sum

indices

that

are

positive

integers), so consider a simple illustration that may defuse this issue. Suppose there are no interior knots (N = 0)

and we consider a quadratic (degree n equal to two hence the ‘spline order’ is three). Then

N i=1−m

contains

three

terms having indices i = −2, −1, 0. In general the number of terms is the number the number of interior knots N

plus the spline order m, which we denote K = N + m. We could alternatively sum from 1 to N + m, or from 0 to

N + m − 1 of from 0 to N + n (the latter being consistent with the B´ezier curve deﬁnition in (1) and the B-spline

deﬁnition in (2)).

A PRIMER ON REGRESSION SPLINES

9

where Y = (Y1, . . . , Yn)T. g (x, z) is estimated by g (x, z) = B (x)T β (z). See the appendix for R code (R Development Core Team (2011)) that implements the B-spline
basis function and then uses least squares to construct the regression model for a simulated data generating process.

References
Aitchison, J. & Aitken, C. G. G. (1976), ‘Multivariate binary discrimination by the kernel method’, Biometrika 63(3), 413–420.
Bernstein, S. (1912), ‘D´emonstration du th´eor`eme de Weierstrass fonde sur le calcul des probabilities’, Comm. Soc. Math. Kharkov 13, 1–2.
de Boor, C. (2001), A practical guide to splines, Springer. Ma, S. & Racine, J. S. (2013), ‘Additive regression splines with irrelevant categorical and continuous regressors’,
Statistica Sinica 23, 515–541. Ma, S., Racine, J. S. & Yang, L. (under revision), ‘Spline regression in the presence of categorical predictors’, Journal
of Applied Econometrics . R Development Core Team (2011), R: A Language and Environment for Statistical Computing, R Foundation for
Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0. URL: http://www.R-project.org/ Racine, J. S. & Nie, Z. (2011), crs: Categorical Regression Splines. R package version 0.14-9. Wahba, G. (1990), Spline Models for Observational Data, SIAM. Zhou, S. & Wolfe, D. A. (2000), ‘On derivative estimation in spline regression’, Statistica Sinica 10, 93–108.

10

JEFFREY S. RACINE

Appendix A. Sample R code for constructing B-splines

The following code uses recursion to compute the B-spline basis and B-spline function. Then a simple illustration demonstrates how one could immediately compute a least-squares ﬁt using the B-spline. In the spirit of recursion, it has been said that “To iterate is human; to recurse divine.” (L. Peter Deutsch).

R Code for Implementing B-spline basis functions and the B-spline itself.
## $Id: spline_primer.Rnw,v 1.29 2013/01/22 17:43:52 jracine Exp jracine $
## April 23 2011. The code below is based upon an illustration that ## can be found in http://www.stat.tamu.edu/~sinha/research/note1.pdf ## by Dr. Samiran Sinha (Department of Statistics, Texas A&M). I am ## solely to blame for any errors and can be contacted at ## racinej@mcmaster.ca (Jeffrey S. Racine).
## This function is a (simplified) R implementation of the bs() ## function in the splines library and illustrates how the Cox-de Boor ## recursion formula is used to construct B-splines.
basis <- function(x, degree, i, knots) { if(degree == 0){ B <- ifelse((x >= knots[i]) & (x < knots[i+1]), 1, 0) } else { if((knots[degree+i] - knots[i]) == 0) { alpha1 <- 0 } else { alpha1 <- (x - knots[i])/(knots[degree+i] - knots[i]) } if((knots[i+degree+1] - knots[i+1]) == 0) { alpha2 <- 0 } else { alpha2 <- (knots[i+degree+1] - x)/(knots[i+degree+1] - knots[i+1]) } B <- alpha1*basis(x, (degree-1), i, knots) + alpha2*basis(x, (degree-1), (i+1), knots) } return(B)
}
bs <- function(x, degree=3, interior.knots=NULL, intercept=FALSE, Boundary.knots = c(0,1)) { if(missing(x)) stop("You must provide x") if(degree < 1) stop("The spline degree must be at least 1") Boundary.knots <- sort(Boundary.knots) interior.knots.sorted <- NULL if(!is.null(interior.knots)) interior.knots.sorted <- sort(interior.knots) knots <- c(rep(Boundary.knots[1], (degree+1)), interior.knots.sorted, rep(Boundary.knots[2], (degree+1))) K <- length(interior.knots) + degree + 1 B.mat <- matrix(0,length(x),K) for(j in 1:K) B.mat[,j] <- basis(x, degree, j, knots) if(any(x == Boundary.knots[2])) B.mat[x == Boundary.knots[2], K] <- 1 if(intercept == FALSE) { return(B.mat[,-1]) } else { return(B.mat) }
}
## A simple illustration that computes and plots the B-spline bases.

A PRIMER ON REGRESSION SPLINES

11

par(mfrow = c(2,1))
n <- 1000 x <- seq(0, 1, length=n) B <- bs(x, degree=5, intercept = TRUE, Boundary.knots=c(0, 1)) matplot(x, B, type="l", lwd=2)
## Next, simulate data then construct a regression spline with a ## prespecified degree (in applied settings we would want to choose ## the degree/knot vector using a sound statistical approach).
dgp <- sin(2*pi*x) y <- dgp + rnorm(n, sd=.1)
model <- lm(y~B-1)
plot(x, y, cex=.25, col="grey") lines(x, fitted(model), lwd=2) lines(x, dgp, col="red", lty=2)

